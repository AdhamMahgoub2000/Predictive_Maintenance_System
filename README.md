Aircraft Engine Failure Imminence Classification (CNN-LSTM)

- Project Overview

This project implements a deep learning‚Äìbased health state classification system for aircraft engines using multivariate time-series sensor data. The goal is to classify engine failure risk rather than predict exact Remaining Useful Life (RUL), which is more robust and actionable in real-world predictive maintenance systems.

The system is built using the NASA CMAPSS Turbofan Engine Degradation Dataset and follows industry-standard practices in data preprocessing, windowed time-series modeling, and deep learning architecture design.

‚∏ª

- Problem Statement

Given historical sensor readings from aircraft engines operating under varying conditions, classify the current health state of an engine into one of two categories:

Class	Description	Risk Level
0	Normal	Low
1	Failure Imminent	High ‚ö†Ô∏è

This binary classification formulation prioritizes early fault detection and safety-critical decision making, using a failure threshold of 30 remaining cycles.

‚∏ª
- Dataset Description

NASA CMAPSS Turbofan Engine Dataset

Each dataset consists of multiple multivariate time series, where each time series represents the full (or partial) operational life of a single engine.

Dataset Variants

Dataset	Train Engines	Test Engines	Operating Conditions	Fault Modes
FD001	100	100	1	1 (HPC degradation)
FD002	260	259	6	1 (HPC degradation)
FD003	100	100	1	2 (HPC + Fan degradation)
FD004	248	249	6	2 (HPC + Fan degradation)

This notebook currently focuses on FD001 as a baseline.

‚∏ª

- Data Format

Each row represents one operational cycle of an engine and contains 26 columns:
	1.	Engine ID
	2.	Cycle number
	3‚Äì5.	Operational settings (included in model)
	6‚Äì26.	Sensor measurements (21 sensors)

‚∏ª

- Exploratory Data Analysis (EDA)

The following preprocessing and EDA steps were completed:
	‚Ä¢	Assigned correct column names
	‚Ä¢	Engine-wise lifecycle visualization
	‚Ä¢	Correlation analysis
	‚Ä¢	Identified and removed globally constant sensors:
	‚Ä¢	sensor_1, sensor_5, sensor_6, sensor_10, sensor_16, sensor_18, sensor_19
	‚Ä¢	Retained 14 informative sensors plus 3 operational settings (17 features total) for modeling

Flat sensor signals were only removed if globally constant, as sensors that activate near failure are informative.

‚∏ª

- Label Engineering (Classification)

The original RUL values were converted into binary health classes:

def convert_to_binary(df, failure_threshold=30):
    df['label'] = (df['RUL'] <= failure_threshold).astype(int)
    return df

Class 0: Normal (RUL > 30 cycles)
Class 1: Failure Imminent (RUL ‚â§ 30 cycles)

This binary classification mapping is used consistently across training, testing, and inference.

‚∏ª

- Time-Series Windowing

To enable deep learning on temporal data, a sliding window approach was used:
	‚Ä¢	Window size: 20 cycles
	‚Ä¢	Step size: 1 cycle
	‚Ä¢	One window ‚Üí one classification label

Training Data
	‚Ä¢	Sliding windows generated across full engine lifecycles
	‚Ä¢	Features include 3 operational settings and 14 sensor measurements (17 features per timestep)
	‚Ä¢	Resulting shape: (N, 20, 17) where N is the number of windows

Test Data
	‚Ä¢	Only the last 20 cycles per engine are used
	‚Ä¢	One prediction per engine
	‚Ä¢	Engines with fewer than 20 cycles are excluded

This follows the official CMAPSS evaluation protocol.

‚∏ª

- Important Design Decisions
	‚Ä¢	Binary classification chosen over regression for robustness and actionability
	‚Ä¢	Failure-imminent class (Class 1) treated as highest-risk
	‚Ä¢	MinMaxScaler applied to sensor columns only; operational settings kept unscaled
	‚Ä¢	Test set kept untouched for final evaluation
	‚Ä¢	Batch size: 32, learning rate: 0.0001, dropout: 0.3

‚∏ª

- Model Architecture

The implemented model uses a CNN-LSTM hybrid architecture:
	‚Ä¢	1D CNN: Two Conv1d layers (64 channels, kernel size 3) for local temporal feature extraction
	‚Ä¢	LSTM: Single-layer LSTM (128 hidden units) for long-term degradation modeling
	‚Ä¢	Fully connected layers: 128 ‚Üí 64 ‚Üí 2 classes with ReLU activations and dropout
	‚Ä¢	Softmax: Health state classification (binary)

Configuration:
	‚Ä¢	Input size: 17 features (3 operational settings + 14 sensors)
	‚Ä¢	CNN channels: 64
	‚Ä¢	LSTM hidden size: 128
	‚Ä¢	LSTM layers: 1
	‚Ä¢	Dropout rates: 0.3 (CNN, LSTM, FC)
	‚Ä¢	Loss function: CrossEntropyLoss
	‚Ä¢	Optimizer: Adam (learning rate: 0.0001)

‚∏ª

- Usage

Training

To train the model:

python train.py

This will load the training data, preprocess it, train the CNN-LSTM model, and save the trained model and scaler to disk.

API Server

To start the FastAPI prediction server:

python predict.py

The API will be available at http://localhost:8080 with interactive documentation at http://localhost:8080/docs.

API Endpoint

POST /predict

Request body (JSON):
	‚Ä¢	features: List of 340 floats (20 timesteps √ó 17 features)
	‚Ä¢	Feature order: [op_set_1, op_set_2, op_set_3, sensor_2, sensor_3, ..., sensor_21] for each timestep

Response:
	‚Ä¢	predicted_class: 0 (Normal) or 1 (Failure Imminent)
	‚Ä¢	confidence: Prediction confidence score (0‚Äì1)

Example Usage

See example_predict.py for complete examples including:
	‚Ä¢	Loading data from test files
	‚Ä¢	Making batch predictions
	‚Ä¢	Simulating engine degradation
	‚Ä¢	Direct model usage (without API)

‚∏ª

- Implementation Status

Completed:
	‚Ä¢	Feature normalization (MinMaxScaler on sensor columns)
	‚Ä¢	PyTorch Dataset & DataLoader implementation
	‚Ä¢	CNN-LSTM model training and evaluation
	‚Ä¢	Model serialization (predictive_maintenance_model.pth, scaler.pkl)
	‚Ä¢	FastAPI REST API deployment (predict.py)
	‚Ä¢	Example prediction scripts and test suite

Files:
	‚Ä¢	train.py: Model training script
	‚Ä¢	predict.py: FastAPI server for predictions
	‚Ä¢	example_predict.py: Usage examples and demonstrations
	‚Ä¢	test_predict.py: Unit tests for API endpoints

Future Enhancements:
	‚Ä¢	Cross-dataset generalization (FD002‚ÄìFD004)
	‚Ä¢	Docker containerization
	‚Ä¢	Model performance metrics dashboard

‚∏ª

üìö Reference

A. Saxena, K. Goebel, D. Simon, and N. Eklund, Damage Propagation Modeling for Aircraft Engine Run-to-Failure Simulation, PHM 2008.

‚∏ª

üë§ Author

Adham Mahgoub

Mechanical Engineer | Machine Learning Engineer

‚∏ª
